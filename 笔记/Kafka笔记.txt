一、概念
	1. kafak是一个分布式发布-订阅模式的消息服务工具，依赖于zookeeper进行工作。
	使用消息队列的好处：
		1)解耦
		  允许对立的扩展或修改两边的处理过程,只要确保它们遵守同样的接口约束
		2)可恢复性
		  系统的每一部分组件失效时,不会影响到整个系统.消息队列降低了进程间的耦合度,
		  所以既是一个处理消息的进程挂掉,加入队列中的消息仍然可以在系统恢复后被处理
		3)缓冲
		  有利于控制和优化数据流经过系统的速度,解决生产消息和消费消息的处理速度
		  不一致的情况
		4)灵活性&峰值处理能力
		  在访问量剧增的情况下,应用仍然需要继续发挥作用,但是这样的突发流量并不常见.
		  以处理这类峰值访问为标准投入资源随时待命是巨大的浪费,使用消息队列能够使关键
		  组件顶住突发的访问压力,而不会因为超负荷的请求而完全崩溃
		5)异步通信
		  消息队列提供了异步处理机制，允许用户把一个消息放入队列但不立即处理，需要的时候再处理
	2.Producer：消息生产者，想kafka发信息的客户端
	  consumer：消息消费者，向kafka broker取消息的客户端
	  consumer group：消费者组，由多个consumer组成
			组内每个消费者消费不同分区数据
			一个分区只能组内一个消费者消费
			消费者组之间不受影响
	  broker：Kafka集群中的每一个服务器都是一个Broker，消费者将从broker拉取
			订阅的消息。一个broker可以容纳多个topic。
	  topic：可以理解为一个队列，生产者和消费者面向的都是一个队列
	  partition：一个topic可以分为多个topic，每个partition都是一个有序的队列
	  replication：副本
	  
	**同一个分区数据,只能被同一个消费者组里的一个消费者消费(同一个消费者组的不同消费者消费不同分区数据提高效率)
	  0.9版本之前偏移量存储在zk,之后版本存储在kafka本地主题
二、kafka命令行操作
	1.kafka-topics.sh
	bin/kafka-topics.sh --list --zookeeper hadoop101:2182    列出当前集群所以主题
	bin/kafka-topics.sh --create --zookeeper hadoop101:2181 --topic first --partitions 2 --replication-factor 2  创建一个名为 first 的分区数为2副本数为2的主题
	bin/kafka-topics.sh --delete --zookeeper hadoop101:2181 --topic first 删除一个主题(delete.topic.enable属性为true才会真正删除，不为true则标记删除)
	bin/kafka-topics.sh --describe --zookeeper hadoop101:2181 --topic first 描述主题
	2.生产者消费者(控制台)
	bin/kafka-console-producer.sh --topic first --broker-list hadoop101:9092  开启一个生产者
	bin/kafka-console-consumer.sh --topic first --bootstrap-server hadoop101:9092 [--from-beginning] [从最小偏移量消费]消费一个主题(连接bootstrap会创建本地主题保存偏移量)
	
三、Kafka架构
	1.工作流程
		topic是逻辑概念，partition是物理概念。每个partition对应一个log文件，主题+分区命名。log文件中存储producer产生的数据。
	producer产生的数据会不断被追加到文件末尾，并且每条数据都有自己的offset。消费者组中的每个消费者都会自己记录自己消费到了哪个
	offset，以便出错恢复时可以从上次的位置继续消费。
	.index文件存储偏移量(n,xx) n:表示第n条消息  xx：表示该消息的起始偏移量。再加上保存的消息长度信息，可以快速在.log文件查询该消息。
	2.生产者
	  1)分区策略
	    分区原因：方便在集群中扩展；提高并发，以partition为单位读取
	  2)分区原则
	    a.指明partition的情况下，直接将指定的值作为partition值
		b.没有指明partition值但有key的情况下，将key的hash值与topic的分区数取余得到partition值
		c.既没有partition又没有key，第一次生成一个随机整数，将这个值与topic的的分区数取余得到partition值(round-robin算法)
	  3)数据可靠性保证
	    概述：为保证producer发送的数据可靠，topic的partition收到producer发送的数据后，需要向topic发送ack确认收到。
		如果producer收到ack，继续发送下一轮消息，否则重发。
		
		kafka副本数据同步策略：全部完成同步，才发送ack。
			这样做的好处是，选举新的leader时，容忍n台故障，只需n+1台机器。缺点：延迟高
			(若其中一台机器挂掉，永远不能发送ack，集群将停止发送消息)
		
		ack：0  不重复发数据。无论leader是否挂掉都可能会丢数据
		     1  leader不挂不会丢数据
			-1  ISR>=2 不会丢数据 producer等待broker的ack，partition的leader和follower全部落盘成功才返回ack。但是如果在follower
			    同步完成后，broker发送ack之前，leader发生故障，会造成数据重复。
		
	    ISR：
		leader维护了一个动态的 in-sync replica set(ISR)。存储了和leader保持一致的follower集合。当ISR中的follower完成同步后，leader就会
		给follower发送ack。如果follower长时间未给leader同步数据，则将该follower踢出ISR。该事件阈值由 replica.lag.time.max.ms 参数设定。
		leader发生故障时，从ISR中选择一个follower作为新的leader。
	
	    **  follower故障时会被踢出ISR，待follower恢复，将读取本地记录的HW(High Watermark)，将log文件高于HW的部分截掉，从HW开始向leader同步，
		follower的LEO(Log End Offset)大于等于该partition的HW，即follower追上leader，就可以重新加入ISR。
		**  Leader故障时会从ISR中选择一个新的leader，其余的follower将log文件的高于HW的部分截掉，然后从新的leader同步数据。
		注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或不重复
	
	3.消费者 
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	