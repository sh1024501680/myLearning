# 面试理论

* ### HDFS写数据流程

![image-20210705205739854](C:\Users\10245\AppData\Roaming\Typora\typora-user-images\image-20210705205739854.png)



```tex
1. client向namenode请求上传文件到指定hdfs路径，namenode检查文件是否存在，父目录是否存在
2. namenode响应可以上传文件
3. client请求第一个 block上传到哪几个datanode服务器上
4. namenode根据集群副本数设置(如副本数为3)，返回dn1，dn2，dn3，表示采用这三个节点存储数据
5. client请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成
6. dn1、dn2、dn3逐级应答客户端
7. 客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答
8. 一个block传输完成之后，客户端再次请求namenode上传第二个block的服务器。(重复执行3-7步)
```



---

* ### HDFS读数据流程

  ![image-20210705210945255](C:\Users\10245\AppData\Roaming\Typora\typora-user-images\image-20210705210945255.png)

```tex
1. client向namenode请求下载文件
2. namenode通过查询元数据，返回文件块所在的datanode地址
3. 挑选一台datanode（就近原则，然后随机）服务器，请求读取数据
4. datanode开始传输数据给客户端，dn返回blk1，blk1传输完成传输blk2(从磁盘里面读取数据放入流，以packet为单位来做校验)
5. 客户端以packet为单位接收，先在本地缓存(放在内存)，然后写入目标文件(合并写入磁盘)
```



---

* ### NameNode工作机制

1.  第一阶段：namenode启动
      	(1) 第一次启动namenode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
      	(2) 客户端对元数据进行增删改的请求(查找不计入日志)
      	(3) namenode记录操作日志，更新滚动日志。
      	(4) namenode在内存中对数据进行增删改查

2. 第二阶段：Secondary NameNode工作
   (1) SecondaryNameNode询问namenode是否需要checkpoint。直接带回namenode是否检查结果。
   		checkpoint触发条件：1. 定时时间到(默认1小时) 2. edits文件数据满了
   		chkpoint参数设置：
   			通常情况下，SecondaryNameNode每隔一小时执行一次。

   ```xml
   [hdfs-default.xml]
   <property>
     <name>dfs.namenode.checkpoint.period</name>
     <value>3600</value>
   </property>
   一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。
   <property>
     <name>dfs.namenode.checkpoint.txns</name>
     <value>1000000</value>
   <description>操作动作次数</description>
   </property>
   
   <property>
     <name>dfs.namenode.checkpoint.check.period</name>
     <value>60</value>
   <description> 1分钟检查一次操作次数</description>
   </property>
   ```

   (2) SecondaryNameNode请求执行checkpoint。
   (3) namenode滚动正在写的edits(假如正在写edits_002)日志(把edits_inprogress重命名为edits_003)，然后新写一个edits_inprogress
   (4) 将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode
   (5) Secondary NameNode加载编辑日志和镜像文件到内存，并合并。
   (6) 生成新的镜像文件fsimage.chkpoint
   (7) 拷贝fsimage.chkpoint到namenode
   (8) namenode将fsimage.chkpoint重新命名成fsimage



---

* ### datanode工作机制

1. datanode工作流程

```xml
(1) datanode启动后要向namenode注册
(2) namenode存储datanode的元数据，回应 注册成功
(3) 周期(1h)上报所有块信息(校验)
(4) 心跳每3秒一次，心跳返回结果带有namenode给datanode的命令
(5) 超过10分钟没有收到某节点心跳，则认为该节点不可用
    定义超时时间为timeout，timeout = 2*dfs.namenode.heartbeat.recheck-interval + 10*dfs.heartbeat.interval

    [hdfs-site.xml]
    <property>
        <name>dfs.namenode.heartbeat.recheck-interval</name>
        <value>300000</value>  单位 ms
    </property>
    <property>
        <name> dfs.heartbeat.interval </name>
        <value>3</value>  单位 s
    </property>
```

2. 数据完整性

```tex
(1) 当DataNode读取block的时候，它会计算checksum
(2) 如果计算后的checksum，与block创建时值不一样，说明block已经损坏
(3) client读取其他DataNode上的block
(4) datanode在其文件创建后周期验证checksum
```



---

* ### HDFS其他功能

  1. 集群间数据拷贝

     ```shell
     hadoop distcp hdfs://hadoop01:8020/test/input/hello.txt hdfs://hadoop04:8020/test/input/hello.txt
     ```

     Hadoop归档
          Hadoop存档文件或HAR文件将文件存入HDFS块，在减少namenode内存使用的同时，允许对文件进行透明的访问
          打包要归档的文件

     ```shell
      hadoop archive -archiveName ss.har -p /user/hadoop/testHar /user/hadoop
     ```

     ​     查看归档

     ```shell
     hadoop fs -lsr har:///user/hadoop/ss.har
     ```

     ​     解归档文件

     ```shell
     hadoop fs -cp har:///user/hadoop/ss.har/* /user/hadoop/
     ```

       快照
          快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。
          （1）hdfs dfsadmin -allowSnapshot 路径   （功能描述：开启指定目录的快照功能）
          （2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）
          （3）hdfs dfs -createSnapshot 路径        （功能描述：对目录创建快照）
          （4）hdfs dfs -createSnapshot 路径 名称   （功能描述：指定名称创建快照）
          （5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）
          （6）hdfs lsSnapshottableDir         （功能描述：列出当前用户所有可快照目录）
          （7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）
          （8）hdfs dfs -deleteSnapshot <path> <snapshotName>  （功能描述：删除快照）

  2. 回收站

     （1）启用回收站
              修改core-site.xml，配置垃圾回收时间为1分钟。

     ```xml
     <property>
          <name>fs.trash.interval</name>
          <value>1</value>
     </property>
     修改访问垃圾回收站用户名称
     进入垃圾回收站用户名称，默认是dr.who，修改为atguigu用户
     <property>
          <name>hadoop.http.staticuser.user</name>
          <value>atguigu</value>
     </property>
     ```

     （2）查看回收站
          回收站在集群中的；路径：/user/atguigu/.Trash/….

     （3）通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站

     ```java
     Trash trash = New Trash(conf);
     trash.moveToTrash(path);
     ```

      （4）恢复回收站数据

     ```shell
     hadoop fs -mv /user/atguigu/.Trash/Current/user/atguigu/input    /user/atguigu/input
     ```

     （5）清空回收站

     ```shell
      hdfs dfs -expunge  并不是删除,而是打一个包 
     ```

     

---

* ### yarn工作流程

（1）Client向ResourceManager提交作业（可以是Spark/Mapreduce作业）

（2）ResourceManager会为这个作业分配一个container

（3）ResourceManager与NodeManager通信，要求NodeManger在刚刚分配好的container上启动应用程序的Application Master

（4）Application Master先去向ResourceManager注册，而后ResourceManager会为各个任务申请资源，并监控运行情况

（5）Application Master采用轮询（polling）方式向ResourceManager申请并领取资源（通过RPC协议通信）

  (6) Application Manager申请到了资源以后，就和NodeManager通信，要求NodeManager启动任务

  最后，NodeManger启动作业对应的任务。 



---

